{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Multi-modal RAG with VertexAI\n",
    "This notebook demonstrates how to implement the Option 2 described [here](load_pdf_multimodal_option2_in_chroma.ipynb) with Generative API on Google Cloud."
   ],
   "id": "ff6fbd95edbb0ce0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6bfa4745284e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:27:38.281807Z",
     "start_time": "2024-11-20T14:27:38.272644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import RedisStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import VertexAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_google_vertexai import ChatVertexAI, VertexAI\n",
    "from redis import Redis\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "load_dotenv(dotenv_path=\"../../.env.research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:26:55.451736Z",
     "start_time": "2024-11-20T14:25:48.708705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=os.getenv(\"DATA_DIR\") + \"/rummikub_rules_with_images.pdf\",\n",
    "    extract_images_in_pdf=True,\n",
    "    infer_table_structure=True,\n",
    "    chunking_strategy=\"by_title\",\n",
    "    max_characters=2500,\n",
    "    new_after_n_chars=2200,\n",
    "    combine_text_under_n_chars=1000,\n",
    "    image_output_dir_path=os.getenv(\"DATA_DIR\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aedb0f900983013",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:26:56.462223Z",
     "start_time": "2024-11-20T14:26:56.458019Z"
    }
   },
   "outputs": [],
   "source": [
    "tables = []\n",
    "texts = []\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "        tables.append(str(element))\n",
    "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        texts.append(str(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e900afaad2f3e3dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:27:44.700580Z",
     "start_time": "2024-11-20T14:27:44.577599Z"
    }
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for VertexAI\n  Value error, Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project [type=value_error, input_value={'temperature': 0, 'max_t... 'default_metadata': ()}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 42\u001B[0m\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m text_summaries, table_summaries\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Get text, table summaries\u001B[39;00m\n\u001B[1;32m---> 42\u001B[0m text_summaries, table_summaries \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_text_summaries\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtables\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msummarize_texts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m     44\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[6], line 19\u001B[0m, in \u001B[0;36mgenerate_text_summaries\u001B[1;34m(texts, tables, summarize_texts)\u001B[0m\n\u001B[0;32m     15\u001B[0m empty_response \u001B[38;5;241m=\u001B[39m RunnableLambda(\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x: AIMessage(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError processing document\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     17\u001B[0m )\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Text summary chain\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mVertexAI\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgemini-pro\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\n\u001B[0;32m     21\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mwith_fallbacks([empty_response])\n\u001B[0;32m     22\u001B[0m summarize_chain \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melement\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mlambda\u001B[39;00m x: x} \u001B[38;5;241m|\u001B[39m prompt \u001B[38;5;241m|\u001B[39m model \u001B[38;5;241m|\u001B[39m StrOutputParser()\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Initialize empty summaries\u001B[39;00m\n",
      "File \u001B[1;32mC:\\pythonenvironments\\IP2AICHAT_3_11\\Lib\\site-packages\\langchain_google_vertexai\\llms.py:122\u001B[0m, in \u001B[0;36mVertexAI.__init__\u001B[1;34m(self, model_name, **kwargs)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_name:\n\u001B[0;32m    121\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_name\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m model_name\n\u001B[1;32m--> 122\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\pythonenvironments\\IP2AICHAT_3_11\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\"\"\"\u001B[39;00m\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\pythonenvironments\\IP2AICHAT_3_11\\Lib\\site-packages\\pydantic\\main.py:212\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[1;34m(self, **data)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001B[39;00m\n\u001B[0;32m    211\u001B[0m __tracebackhide__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 212\u001B[0m validated_self \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__pydantic_validator__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mself_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m validated_self:\n\u001B[0;32m    214\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    215\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA custom validator is returning a value other than `self`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    216\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReturning anything other than `self` from a top level model validator isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt supported when validating via `__init__`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    217\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    218\u001B[0m         category\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    219\u001B[0m     )\n",
      "\u001B[1;31mValidationError\u001B[0m: 1 validation error for VertexAI\n  Value error, Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project [type=value_error, input_value={'temperature': 0, 'max_t... 'default_metadata': ()}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error"
     ]
    }
   ],
   "source": [
    "def generate_text_summaries(texts, tables, summarize_texts=False):\n",
    "    \"\"\"\n",
    "    Summarize text elements\n",
    "    texts: List of str\n",
    "    tables: List of str\n",
    "    summarize_texts: Bool to summarize texts\n",
    "    \"\"\"\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    The text is about the rules of Rummikub. \\\n",
    "    Give a concise summary of the table or text that is well optimized for retrieval. Table or text: {element} \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_text)\n",
    "    empty_response = RunnableLambda(\n",
    "        lambda x: AIMessage(content=\"Error processing document\")\n",
    "    )\n",
    "    # Text summary chain\n",
    "    model = VertexAI(\n",
    "        temperature=0, model_name=\"gemini-pro\", max_tokens=1024\n",
    "    ).with_fallbacks([empty_response])\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # Initialize empty summaries\n",
    "    text_summaries = []\n",
    "    table_summaries = []\n",
    "\n",
    "    # Apply to text if texts are provided and summarization is requested\n",
    "    if texts and summarize_texts:\n",
    "        text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 1})\n",
    "    elif texts:\n",
    "        text_summaries = texts\n",
    "\n",
    "    # Apply to tables if tables are provided\n",
    "    if tables:\n",
    "        table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 1})\n",
    "\n",
    "    return text_summaries, table_summaries\n",
    "\n",
    "\n",
    "text_summaries, table_summaries = generate_text_summaries(\n",
    "    texts, tables, summarize_texts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45427e2f23eb898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    \"\"\"Getting the base64 string\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def image_summarize(img_base64, prompt):\n",
    "    \"\"\"Make image summary\"\"\"\n",
    "    model = ChatVertexAI(model_name=\"gemini-pro-vision\", max_tokens=1024)\n",
    "\n",
    "    msg = model.invoke(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=[\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"},\n",
    "                    },\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    return msg.content\n",
    "\n",
    "\n",
    "def generate_img_summaries(path):\n",
    "    \"\"\"\n",
    "    Generate summaries and base64 encoded strings for images\n",
    "    path: Path to list of .jpg files extracted by Unstructured\n",
    "    \"\"\"\n",
    "\n",
    "    # Store base64 encoded images\n",
    "    img_base64_list = []\n",
    "\n",
    "    # Store image summaries\n",
    "    image_summaries = []\n",
    "\n",
    "    # Prompt\n",
    "    prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
    "    The images are from a document about the rules of Rummikub. \\\n",
    "    These summaries will be embedded and used to retrieve the raw image. \\\n",
    "    Give a concise summary of the image that is well optimized for retrieval.\"\"\"\n",
    "\n",
    "    # Apply to images\n",
    "    for img_file in sorted(os.listdir(path)):\n",
    "        if img_file.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(path, img_file)\n",
    "            base64_image = encode_image(img_path)\n",
    "            img_base64_list.append(base64_image)\n",
    "            image_summaries.append(image_summarize(base64_image, prompt))\n",
    "\n",
    "    return img_base64_list, image_summaries\n",
    "\n",
    "\n",
    "# Image summaries\n",
    "img_base64_list, image_summaries = generate_img_summaries(os.getenv(\"IMG_DIR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91232f68803a8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_vector_retriever(\n",
    "    vectorstore, text_summaries, texts, table_summaries, tables, image_summaries, images\n",
    "):\n",
    "    \"\"\"\n",
    "    Create retriever that indexes summaries, but returns raw images or texts\n",
    "    \"\"\"\n",
    "\n",
    "    redis_client = Redis(\n",
    "        host=os.getenv(\"REDIS_HOST\"),\n",
    "        port=int(os.getenv(\"REDIS_PORT\")),\n",
    "        password=os.getenv(\"REDIS_PASSWORD\"),\n",
    "    )\n",
    "    doc_store = RedisStore(client=redis_client)\n",
    "    id_key = \"doc_id\"\n",
    "\n",
    "    # Create the multi-vector retriever\n",
    "    retriever = MultiVectorRetriever(\n",
    "        vectorstore=vectorstore,\n",
    "        docstore=doc_store,\n",
    "        id_key=id_key,\n",
    "    )\n",
    "\n",
    "    # Helper function to add documents to the vectorstore and docstore\n",
    "    def add_documents(retriever, doc_summaries, doc_contents):\n",
    "        doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
    "        summary_docs = [\n",
    "            Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "            for i, s in enumerate(doc_summaries)\n",
    "        ]\n",
    "        retriever.vectorstore.add_documents(summary_docs)\n",
    "        retriever.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
    "\n",
    "    # Add texts, tables, and images\n",
    "    # Check that text_summaries is not empty before adding\n",
    "    if text_summaries:\n",
    "        add_documents(retriever, text_summaries, texts)\n",
    "    # Check that table_summaries is not empty before adding\n",
    "    if table_summaries:\n",
    "        add_documents(retriever, table_summaries, tables)\n",
    "    # Check that image_summaries is not empty before adding\n",
    "    if image_summaries:\n",
    "        add_documents(retriever, image_summaries, images)\n",
    "\n",
    "    return retriever\n",
    "\n",
    "\n",
    "client = chromadb.HttpClient(host=\"localhost\", port=5000)\n",
    "\n",
    "if \"rummikub_rules\" in client.list_collections():\n",
    "    client.delete_collection(\"rummikub_rules\")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"rummikub_rules\",\n",
    "    embedding_function=VertexAIEmbeddings(model_name=\"textembedding-gecko@latest\"),\n",
    "    client=client,\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever_multi_vector_img = create_multi_vector_retriever(\n",
    "    vectorstore,\n",
    "    text_summaries,\n",
    "    texts,\n",
    "    table_summaries,\n",
    "    tables,\n",
    "    image_summaries,\n",
    "    img_base64_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9014f85f1430dedd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Interesting and works if you have a Google cloud api key. But because it is expensive we will not use this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
