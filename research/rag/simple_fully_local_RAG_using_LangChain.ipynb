{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c948b15d",
   "metadata": {},
   "source": [
    "# Simple Fully Local RAG Agents Using LangChain with LLaMA3.2\n",
    "\n",
    "The purpose is to build a fully local RAG (Retrieval-Augmented Generation) system leveraging LLaMA3.2 as the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d731e069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:51:40.511962Z",
     "start_time": "2024-11-26T16:51:40.390146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv(\"../../.env.research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e8695d2922100b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:51:41.659553Z",
     "start_time": "2024-11-26T16:51:40.648290Z"
    }
   },
   "outputs": [],
   "source": [
    "### LLM\n",
    "local_llm = \"llama3.2:latest\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac8e2ee07625984b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:51:41.721840Z",
     "start_time": "2024-11-26T16:51:41.712409Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_pdfs_from_directory(directory_path):\n",
    "    all_documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            loader = PDFPlumberLoader(file_path=file_path)\n",
    "            documents = loader.load()\n",
    "            all_documents.extend(documents)\n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dc585a8400348c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:51:43.797739Z",
     "start_time": "2024-11-26T16:51:41.736397Z"
    }
   },
   "outputs": [],
   "source": [
    "client = chromadb.HttpClient(\n",
    "    host=os.getenv(\"CHROMA_HOST\"), port=int(os.getenv(\"CHROMA_PORT\"))\n",
    ")\n",
    "vectorstore = None\n",
    "if os.getenv(\"CHROMA_COLLECTION_NAME\") not in [\n",
    "    collection.name for collection in client.list_collections()\n",
    "]:\n",
    "    client.create_collection(os.getenv(\"CHROMA_COLLECTION_NAME\"))\n",
    "    pdf_docs = load_pdfs_from_directory(os.getenv(\"DATA_DIR\"))\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)\n",
    "    all_splits = text_splitter.split_documents(pdf_docs)\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=all_splits,\n",
    "        embedding=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "        collection_name=os.getenv(\"CHROMA_COLLECTION_NAME\"),\n",
    "        client=client,\n",
    "    )\n",
    "else:\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=os.getenv(\"CHROMA_COLLECTION_NAME\"),\n",
    "        client=client,\n",
    "        embedding_function=OllamaEmbeddings(model=\"nomic-embed-text\"),\n",
    "    )\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed3cbf00047c02a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:51:43.822495Z",
     "start_time": "2024-11-26T16:51:43.816832Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "101e73e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:51:43.851032Z",
     "start_time": "2024-11-26T16:51:43.838560Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fec86eba4ce0fc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:51:43.888823Z",
     "start_time": "2024-11-26T16:51:43.877093Z"
    }
   },
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "420b425a4f62c1a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:52:05.488814Z",
     "start_time": "2024-11-26T16:51:43.903370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know. The provided context doesn't mention the capital of France or any information about geography.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\": \"What is the capital of France?\"})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2153ffe56c3a07c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:52:30.197800Z",
     "start_time": "2024-11-26T16:52:05.503368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A joker can be used as a substitute for any numbered tile of any color to make up a valid combination, and its value counts as the value of the tile it represents.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\": \"What do I use a joker for?\"})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd533aa987cca7c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:52:56.715015Z",
     "start_time": "2024-11-26T16:52:30.216608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are three ways to win in Rummikub: Open, Foot, and Closed. The specific rules for each type of win vary, but the general goal is to get rid of all your tiles by melding them into valid groups or runs.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\": \"How can I win?\"})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e29b778938dd1651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T16:53:30.639145Z",
     "start_time": "2024-11-26T16:52:56.724554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Manipulatie is de meest opwindende deler van het spel Rummikub. Spelers proberen de grootste hoeveelheid tiles te tafelen door de best mogelijke sets aan te passen of toe te voegen aan bestaande sets op de tafel.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\": \"Wat is manipulatie?\"})[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d17f14afdd06",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Easy to use, but there is no check whether the answer is correct or not. So this is a rather a fallback if the langgraph chatbot is too challenging to implement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
