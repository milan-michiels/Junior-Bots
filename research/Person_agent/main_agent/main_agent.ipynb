{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:21:46.018015Z",
     "start_time": "2025-03-08T13:21:45.300384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import List\n",
    "from typing import TypedDict\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.constants import END\n",
    "from langgraph.graph import StateGraph\n",
    "from pydantic import BaseModel\n",
    "from research.Person_agent.email_agent import email_agent"
   ],
   "id": "b0c8d2f756654342",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-08T13:21:46.760850Z",
     "start_time": "2025-03-08T13:21:46.027557Z"
    }
   },
   "source": [
    "### LLM\n",
    "local_llm = str(os.getenv(\"LLM_MODEL\"))\n",
    "llm = ChatOllama(model=local_llm, temperature=0.0)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:21:46.774534Z",
     "start_time": "2025-03-08T13:21:46.770387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Tool utilities\n",
    "\n",
    "tools_utilities_instructions = \"\"\"\n",
    "You are an AI Doppelganger, your primary task is to act as an autonomous agent that performs tasks on behalf of the user, mimicking their personality, preferences and behavior across various tasks. You’ll retrieve necessary data and make decisions based on the user’s history, priorities, and communication style. Always ensure user privacy and consent, and remember to operate within ethical boundaries. There are several tools you can use to assist the user.\n",
    "\n",
    "Tools:\n",
    "\n",
    "1. **Email Analyzer**: Analyze the user’s email to summarize, categorize, and prioritize tasks. If necessary, draft responses.\n",
    "2. **Social Media Manager**: Assist the user in engaging, commenting and posting while using the user's preferences and input.\n",
    "\"\"\"\n",
    "\n",
    "tools_utilities_prompt = \"\"\"\n",
    "Define the tool(s) you need to use based on the input you receive and the personal information you have access to.\n",
    "\n",
    "Output the tool(s) you will use and the reason for using them.\n",
    "\n",
    "Users personal data:\n",
    "\n",
    "{personal_data}\n",
    "\n",
    "Input:\n",
    "\n",
    "{input}\n",
    "\"\"\""
   ],
   "id": "caf5c03f3185afff",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:21:46.790847Z",
     "start_time": "2025-03-08T13:21:46.784959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "validations_instructions = \"\"\"\n",
    "You are a supervisor tasked with validating the tool that is chosen to be used by the AI Doppelganger.\n",
    "\n",
    "You are to ensure that the tool is able to generate responses that are coherent, relevant, and grounded in the facts provided.\n",
    "You are to provide feedback on the tool's performance and suggest improvements where necessary.\n",
    "\n",
    "Provide your answer as \"yes\" or \"no\" and give reasons for your choice.\n",
    "\"\"\"\n",
    "\n",
    "validations_prompt = \"\"\"\n",
    "Validate the tool(s) chosen by the AI Doppelganger based on the input provided.\n",
    "\n",
    "Input:\n",
    "\n",
    "{input}\n",
    "\n",
    "Tool(s) chosen:\n",
    "\n",
    "{tools}\n",
    "\"\"\""
   ],
   "id": "c970170f19f78744",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:21:46.814580Z",
     "start_time": "2025-03-08T13:21:46.810454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Models\n",
    "\n",
    "class Tool(BaseModel):\n",
    "    tools: List[str]\n"
   ],
   "id": "a471b5c8804579c2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:21:46.838546Z",
     "start_time": "2025-03-08T13:21:46.834500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### State\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    input: str\n",
    "    personal_data: str\n",
    "    validation: str\n",
    "    tools: List[str]\n",
    "    next_tool: str\n",
    "\n",
    "\n",
    "class InvokeToolsOutputState(TypedDict):\n",
    "    tools: List[str]\n",
    "    next_tool: str"
   ],
   "id": "e9d514630c490a17",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:21:46.867930Z",
     "start_time": "2025-03-08T13:21:46.862406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Nodes\n",
    "\n",
    "def tool_utilities(state: OverallState):\n",
    "    personal = state[\"personal_data\"]\n",
    "    input = state[\"input\"]\n",
    "    tools_utilities_prompt.format(\n",
    "        personal_data=personal,\n",
    "        input=input\n",
    "    )\n",
    "    tool_llm = llm.with_structured_output(Tool)\n",
    "    tool_response: Tool = tool_llm.invoke([\n",
    "        SystemMessage(content=tools_utilities_instructions),\n",
    "        HumanMessage(content=tools_utilities_prompt),\n",
    "    ])\n",
    "    return {\"tools\": tool_response.tools}\n",
    "\n",
    "\n",
    "def validate_tools(state: OverallState) -> OverallState:\n",
    "    pass\n",
    "\n",
    "\n",
    "def invoke_tool(state: OverallState) -> InvokeToolsOutputState:\n",
    "    tools = state[\"tools\"]\n",
    "    next_tool = tools[0]\n",
    "    state[\"tools\"] = tools[1:]\n",
    "    return {\"tools\": state[\"tools\"], \"next_tool\": next_tool}"
   ],
   "id": "57c2e310837e53a3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T13:21:47.048947Z",
     "start_time": "2025-03-08T13:21:46.885607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.core.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "### Workflow\n",
    "\n",
    "main_agent = StateGraph(OverallState)\n",
    "\n",
    "main_agent.add_node(\"tool_utilities\", tool_utilities)\n",
    "main_agent.add_node(\"validate_tools\", validate_tools)\n",
    "main_agent.add_node(\"email_analyzer\", email_agent.compile())\n",
    "main_agent.add_node(\"social_media_manager\", lambda state: state)\n",
    "\n",
    "main_agent.set_entry_point(\"tool_utilities\")\n",
    "main_agent.add_edge(\"tool_utilities\", \"validate_tools\")\n",
    "main_agent.add_conditional_edges(\"validate_tools\", lambda state: invoke_tool(state)[\"next_tool\"], {\n",
    "    \"email\": \"email_analyzer\",\n",
    "    \"social\": \"social_media_manager\",\n",
    "})\n",
    "main_agent.add_edge(\"email_analyzer\", END)\n",
    "main_agent.add_edge(\"social_media_manager\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = main_agent.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "91527b796259ae2a",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'module'>",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m main_agent.add_node(\u001B[33m\"\u001B[39m\u001B[33mtool_utilities\u001B[39m\u001B[33m\"\u001B[39m, tool_utilities)\n\u001B[32m      9\u001B[39m main_agent.add_node(\u001B[33m\"\u001B[39m\u001B[33mvalidate_tools\u001B[39m\u001B[33m\"\u001B[39m, validate_tools)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m \u001B[43mmain_agent\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd_node\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43memail_analyzer\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43memail_agent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m main_agent.add_node(\u001B[33m\"\u001B[39m\u001B[33msocial_media_manager\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mlambda\u001B[39;00m state: state)\n\u001B[32m     13\u001B[39m main_agent.set_entry_point(\u001B[33m\"\u001B[39m\u001B[33mtool_utilities\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\pythonenvironments\\NORTH_STAR_HACKATHON\\Lib\\site-packages\\langgraph\\graph\\state.py:418\u001B[39m, in \u001B[36mStateGraph.add_node\u001B[39m\u001B[34m(self, node, action, metadata, input, retry, destinations)\u001B[39m\n\u001B[32m    415\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    416\u001B[39m     \u001B[38;5;28mself\u001B[39m._add_schema(\u001B[38;5;28minput\u001B[39m)\n\u001B[32m    417\u001B[39m \u001B[38;5;28mself\u001B[39m.nodes[cast(\u001B[38;5;28mstr\u001B[39m, node)] = StateNodeSpec(\n\u001B[32m--> \u001B[39m\u001B[32m418\u001B[39m     \u001B[43mcoerce_to_runnable\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrace\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m,\n\u001B[32m    419\u001B[39m     metadata,\n\u001B[32m    420\u001B[39m     \u001B[38;5;28minput\u001B[39m=\u001B[38;5;28minput\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.schema,\n\u001B[32m    421\u001B[39m     retry_policy=retry,\n\u001B[32m    422\u001B[39m     ends=ends,\n\u001B[32m    423\u001B[39m )\n\u001B[32m    424\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\pythonenvironments\\NORTH_STAR_HACKATHON\\Lib\\site-packages\\langgraph\\utils\\runnable.py:429\u001B[39m, in \u001B[36mcoerce_to_runnable\u001B[39m\u001B[34m(thing, name, trace)\u001B[39m\n\u001B[32m    427\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m RunnableParallel(thing)\n\u001B[32m    428\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m429\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    430\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExpected a Runnable, callable or dict.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    431\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mInstead got an unsupported type: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(thing)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    432\u001B[39m     )\n",
      "\u001B[31mTypeError\u001B[39m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'module'>"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
