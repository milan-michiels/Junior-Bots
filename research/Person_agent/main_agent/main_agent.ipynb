{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "from typing import List\n",
    "from typing import TypedDict\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.stores import BaseStore\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.constants import END\n",
    "from langgraph.graph import StateGraph\n",
    "from pydantic import BaseModel\n",
    "from IPython.core.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ],
   "id": "b0c8d2f756654342"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "# import constants\n",
    "from constants import (\n",
    "    RES_GOOD,\n",
    "    RES_INFO_NOT_SUFFICIENT,\n",
    "    RES_NOT_GOOD,\n",
    "    MAX_ATTEMPTS,\n",
    "    TOOL_EMAIL,\n",
    "    TOOL_MEDIA,\n",
    "    TOOL_MAIN_AGENT\n",
    ")"
   ],
   "id": "1219ab40ae50aa80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LLM\n",
    "local_llm = str(os.getenv(\"LLM_MODEL\"))\n",
    "llm = ChatOllama(model=local_llm, temperature=0.0)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:51:14.093028Z",
     "start_time": "2025-03-08T11:51:14.089029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Tool utilities\n",
    "\n",
    "tools_utilities_instructions = \"\"\"\n",
    "You are an AI Doppelganger, your primary task is to act as an autonomous agent that performs tasks on behalf of the user, mimicking their personality, preferences and behavior across various tasks. You’ll retrieve necessary data and make decisions based on the user’s history, priorities, and communication style. Always ensure user privacy and consent, and remember to operate within ethical boundaries. There are several tools you can use to assist the user.\n",
    "\n",
    "Tools:\n",
    "\n",
    "1. **Email Analyzer**: Analyze the user’s email to summarize, categorize, and prioritize tasks. If necessary, draft responses.\n",
    "2. **Social Media Manager**: Assist the user in engaging, commenting and posting while using the user's preferences and input.\n",
    "\"\"\"\n",
    "\n",
    "tools_utilities_prompt = \"\"\"\n",
    "Define the tool(s) you need to use based on the input you receive and the personal information you have access to.\n",
    "\n",
    "Output the tool(s) you will use and the reason for using them.\n",
    "\n",
    "Users personal data:\n",
    "\n",
    "{personal_data}\n",
    "\n",
    "Input:\n",
    "\n",
    "{input}\n",
    "\"\"\""
   ],
   "id": "caf5c03f3185afff",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:51:14.231505Z",
     "start_time": "2025-03-08T11:51:14.229127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "validations_instructions = \"\"\"\n",
    "You are a supervisor tasked with validating the tool that is chosen to be used by the AI Doppelganger.\n",
    "\n",
    "You are to ensure that the tool is able to generate responses that are coherent, relevant, and grounded in the facts provided.\n",
    "You are to provide feedback on the tool's performance and suggest improvements where necessary.\n",
    "\n",
    "Provide your answer as \"yes\" or \"no\" and give reasons for your choice.\n",
    "\"\"\"\n",
    "\n",
    "validations_prompt = \"\"\"\n",
    "Validate the tool(s) chosen by the AI Doppelganger based on the input provided.\n",
    "\n",
    "Input:\n",
    "\n",
    "{input}\n",
    "\n",
    "Tool(s) chosen:\n",
    "\n",
    "{tools}\n",
    "\"\"\""
   ],
   "id": "c970170f19f78744",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Models\n",
    "\n",
    "class Tool(BaseModel):\n",
    "    tools: List[str]\n"
   ],
   "id": "a471b5c8804579c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### State\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    input: str\n",
    "    validation: str\n",
    "    tools: List[str]\n",
    "    next_tool: str\n",
    "\n",
    "\n",
    "class InvokeToolsOutputState(TypedDict):\n",
    "    tools: List[str]\n",
    "    next_tool: str"
   ],
   "id": "e9d514630c490a17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "### Nodes\n",
    "\n",
    "def tool_utilities(state: OverallState, config:RunnableConfig,store:BaseStore):\n",
    "    input = state[\"input\"]\n",
    "    user_id=config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    namespace=(\"profile\", user_id)\n",
    "\n",
    "    tools_utilities_prompt.format(\n",
    "        personal_data=personal,\n",
    "        input=input\n",
    "    )\n",
    "    tool_llm = llm.with_structured_output(Tool)\n",
    "    tool_response: Tool = tool_llm.invoke([\n",
    "        SystemMessage(content=tools_utilities_instructions),\n",
    "        HumanMessage(content=tools_utilities_prompt),\n",
    "    ])\n",
    "    return {\"tools\": tool_response.tools}\n",
    "\n",
    "\n",
    "def validate_tools(state: OverallState) -> OverallState:\n",
    "    ret = {\n",
    "        \"validation\": \"\",\n",
    "        \"num_attempts\": 0\n",
    "    }\n",
    "    num_attempts = state[\"num_attempts\"]\n",
    "    tools = state[\"tools\"]\n",
    "    if tools != TOOL_MAIN_AGENT:\n",
    "        return ret\n",
    "\n",
    "    if num_attempts == MAX_ATTEMPTS:\n",
    "        ret['validation'] = RES_INFO_NOT_SUFFICIENT\n",
    "        ret[\"num_attempts\"] = 0 # reset attempts\n",
    "    else:\n",
    "        input = state[\"input\"]\n",
    "        validations_prompt.format(\n",
    "            input=input,\n",
    "            tools=tools\n",
    "        )\n",
    "        val_llm = llm.with_structured_output(Tool)\n",
    "        val_response: Tool = val_llm.invoke([\n",
    "            SystemMessage(content=validations_instructions),\n",
    "            HumanMessage(content=validations_prompt),\n",
    "        ])\n",
    "        if val_response.tools[0] == RES_GOOD:\n",
    "            ret['validation'] = RES_GOOD\n",
    "        elif val_response.tools[0] == RES_NOT_GOOD:\n",
    "            ret['validation'] = RES_NOT_GOOD\n",
    "        else:\n",
    "            ret['num_attempts'] += 1\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def invoke_tool(state: OverallState) -> InvokeToolsOutputState:\n",
    "    tools = state[\"tools\"]\n",
    "    next_tool = tools[0]\n",
    "    state[\"tools\"] = tools[1:]\n",
    "    return {\"tools\": state[\"tools\"], \"next_tool\": next_tool}"
   ],
   "id": "57c2e310837e53a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "main_agent = StateGraph(OverallState)\n",
    "\n",
    "main_agent.add_node(\"tool_utilities\", tool_utilities)\n",
    "main_agent.add_node(\"validate_tools\", validate_tools)\n",
    "main_agent.add_node(\"email_analyzer\", lambda state: state)\n",
    "main_agent.add_node(\"social_media_manager\", lambda state: state)\n",
    "\n",
    "main_agent.set_entry_point(\"tool_utilities\")\n",
    "main_agent.add_edge(\"tool_utilities\", \"validate_tools\")\n",
    "main_agent.add_conditional_edges(\"validate_tools\", lambda state: invoke_tool(state)[\"next_tool\"], {\n",
    "    \"email\": \"email_analyzer\",\n",
    "    \"social\": \"social_media_manager\",\n",
    "})\n",
    "main_agent.add_edge(\"email_analyzer\", END)\n",
    "main_agent.add_edge(\"social_media_manager\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = main_agent.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "91527b796259ae2a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
